{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CHAT BOT\n",
    "\n",
    "Importing basic numpy , matplotlib , pandas libraries for array functionalities and dataframe operations \n",
    "Importing Datetime , dateutil for date time analysis and operations . dparser to identify date i the format of YYYY-MM-DD\n",
    "Importing Pyspark to perform SQL queries in a fast manner\n",
    "\n",
    "Pysaprk is used as it provides very effective and fast dataframe processing using RDD \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "isSubstring(s1, s2):   checks for Substring of s1 from s2 \n",
    "\n",
    "date_find(c):          checks what date the users wants to analyze the data , c is an input String by default todat \n",
    "\n",
    "numer(i):              checks how the date is embedded with number of prior week and months , where both present will take the most recent \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top brands on 2018-07-01 \n",
      "'2018-07-01 00:00:00'\n",
      "2019-03-07\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "### Importing Data Analytical Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil.parser as dparser\n",
    "today = date.today()\n",
    "\n",
    "#dataset = pd.read_csv('Admission_Predict.csv')\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#dataset_ps = spark.createDataFrame(dataset)\n",
    "\n",
    "def isSubstring(s1, s2): \n",
    "    M = len(s1) \n",
    "    N = len(s2) \n",
    "  \n",
    "    # A loop to slide pat[] one by one  \n",
    "    for i in range(N - M + 1): \n",
    "  \n",
    "        # For current index i, \n",
    "        # check for pattern match  \n",
    "        for j in range(M): \n",
    "            if (s2[i + j] != s1[j]): \n",
    "                break\n",
    "              \n",
    "        if j + 1 == M : \n",
    "            return i \n",
    "  \n",
    "    return -1\n",
    "\n",
    "def date_find(c):\n",
    "    t=today\n",
    "    #print(len(c))\n",
    "    for i in range(0,len(c)):\n",
    "         if c[i] =='today':\n",
    "            t=t \n",
    "            return t;\n",
    "            #print(t)\n",
    "         elif c[i] =='yesterday':\n",
    "            t=t+timedelta(days=-1)\n",
    "            #print(t)\n",
    "            return t;\n",
    "         elif c[i] == 'week':\n",
    "            y=numer(i)\n",
    "            t=t+timedelta(weeks=-1*y)\n",
    "            #print(t)\n",
    "         elif c[i] == 'month':\n",
    "            y=numer(i)\n",
    "            t=t+relativedelta(months=-1*y)\n",
    "            #print(t)\n",
    "         elif c[i] == 'year':\n",
    "            y=numer(i)\n",
    "            t=t+relativedelta(years=-1*y)\n",
    "            #print(t)\n",
    "        \n",
    "    return t;\n",
    "\n",
    "\n",
    "def date_spec_find(c):\n",
    "    list1 =[]\n",
    "    lt1=''\n",
    "    for i in range (0,len(c)):\n",
    "        try:\n",
    "            dt = dparser.parse(c[i],fuzzy =True).date()\n",
    "            dt=str(dt)\n",
    "            list1.append(dt)\n",
    "            lt1=lt1+\"'\"+str(c[i])+\" 00:00:00'\"+\",\"\n",
    "        except:\n",
    "            dt = 0\n",
    "            \n",
    "    lt1=lt1[0:(len(lt1)-1)]\n",
    "    return lt1\n",
    "\n",
    "\n",
    "def numer(i):\n",
    "    num ={\n",
    "        \"one\":1,\n",
    "        \"first\":1,\n",
    "        \"two\":2,\n",
    "        \"second\":2,\n",
    "        \"three\":3,\n",
    "        \"third\":3,\n",
    "        \"four\":4,\n",
    "        \"fourth\":4,\n",
    "        \"fifth\":5,\n",
    "        \"five\":5,\n",
    "        \"six\":6,\n",
    "        \"sixth\":6,\n",
    "        \"seven\":7,\n",
    "        \"seventh\":7,\n",
    "        \"eight\":8,\n",
    "        \"eighth\":8,\n",
    "        \"nine\":9,\n",
    "        \"ninth\":9\n",
    "    }\n",
    "    #print(num)\n",
    "    for j in range(0,i):\n",
    "            #print(c[j])\n",
    "            if c[j] in num:\n",
    "                #print(\"hgghhj\")\n",
    "                a= num[c[j]]\n",
    "            else:\n",
    "                a=0     \n",
    "        \n",
    "    if a==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return a\n",
    "                \n",
    "### Basic analysis : -- >(Data understanding)\n",
    "print('ARTICLES -- > ')\n",
    "df=spark.read.csv('articles.csv',inferSchema=True,header=True)\n",
    "df.show(10,False)\n",
    "print('HIERARCHY -- > ')\n",
    "df1=spark.read.csv('hierarchy.csv',inferSchema=True,header=True)\n",
    "df1.show(10,False)\n",
    "print('BILLS -- > ')\n",
    "df2=spark.read.csv('bills.csv',inferSchema=True,header=True)\n",
    "df2.show(10,False)\n",
    "\n",
    "### Removing Deplicacy: ---> (DATA PREPROCESSING )\n",
    "df.dropDuplicates().createOrReplaceTempView(\"Article\")\n",
    "df1.dropDuplicates().createOrReplaceTempView(\"Hierarchy\")\n",
    "df2.dropDuplicates().createOrReplaceTempView(\"Bills\")\n",
    "\n",
    "\n",
    "### Checking for catalog list in Spark SQL DATABASE\n",
    "print(spark.catalog.listTables())\n",
    "\n",
    "### Creating Categorical Variable DataFrame category_name\n",
    "qu = \"select distinct category_name from hierarchy\"\n",
    "category_name = spark.sql(qu)\n",
    "category_name.show()\n",
    "\n",
    "### Creating Categorical Variable DataFrame subcategory_name\n",
    "qu1 = \"select distinct subcategory_name from hierarchy\"\n",
    "subcategory_name = spark.sql(qu1)\n",
    "subcategory_name.show()\n",
    "\n",
    "### Creating Categorical Variable DataFrame brand_name\n",
    "qu2 = \"select distinct brand_name from hierarchy\"\n",
    "brand_name = spark.sql(qu2)\n",
    "brand_name.show()\n",
    "\n",
    "\n",
    "### Analysis (Data Testing (if Required))\n",
    "#query = \"select sum(total_price) from bills where sale_date = '2018-07-07 00:00:00'\"\n",
    "#f = spark.sql(query)\n",
    "#f.show()\n",
    "#\n",
    "\n",
    "#query1 =\"select sum(total_price) from hierarchy as h join bills as b where h.article_id = b.article_id and brand_name = 'parle' \"\n",
    "#query1 = \"select sum(total_price) from bills where article_id in(select article_id  from  hierarchy where brand_name = 'parle') \"\n",
    "#f1 = spark.sql(query1)\n",
    "#f1.show()\n",
    "#\n",
    "\n",
    "#query = \"SELECT * from bills where sale_date = '\"+str(t)+\" 00:00:00'  \"\n",
    "#f = spark.sql(query)\n",
    "#f.show()\n",
    "#\n",
    "\n",
    "#query = \"SELECT count(*) from bills   \"\n",
    "#f = spark.sql(query)\n",
    "#f.show()\n",
    "#\n",
    "\n",
    "\n",
    "chatentry = input()\n",
    "chatentry=\" \"+chatentry+\" \"\n",
    "chatentry=chatentry.lower()\n",
    "c=chatentry.split();\n",
    "\n",
    "\n",
    "### Variable Understanding\n",
    "# tp corresponds to total price or sales presence as 1 or 0\n",
    "# qt corresponds to quantity presence as 1 or 0\n",
    "# nm corresponds to number of sales presence as 1 or 0\n",
    "# c1 corresonds to the list of categorical variables presents checked from dataframe df\n",
    "# subc corresonds to the list of sub-categorical variables presents checked from dataframe df1\n",
    "# bn1 corresonds to the list of brand variables presents checked from dataframe df2\n",
    "#cn corresponds to categorical Variables presence as 1 or 0\n",
    "#scn corresponds to sub categorical Variable presence as 1 or 0\n",
    "#bn corresponds to brand Variable presence as 1 or 0\n",
    "#gbn corrsponds to the list broken to '' seprated by , of brand list bn1\n",
    "#ebn corrsponds to the list broken to '' seprated by , of sub-categorical list subc\n",
    "#cbn corrsponds to the list broken to '' seprated by , of categorical list bc1\n",
    "topa=0\n",
    "topb=0\n",
    "tp=0\n",
    "nm=0\n",
    "qt=0\n",
    "cn=0\n",
    "scn=0\n",
    "bn=0\n",
    "gbn=''\n",
    "ebn=''\n",
    "cbn=''\n",
    "c1=[]\n",
    "subc=[]\n",
    "bn1=[]\n",
    "\n",
    "\n",
    "### Converting Data frames to Pandas so that we can work with pandas dataframe in easier and computationally faster fashion\n",
    "#df is categorical\n",
    "#df1 is sub-categorical\n",
    "#df2 is brand\n",
    "\n",
    "df=category_name.toPandas() \n",
    "df1=subcategory_name.toPandas()\n",
    "df2=brand_name.toPandas()\n",
    "\n",
    "### Finding Date in variable t and dt \n",
    "\n",
    "dt=date_spec_find(c)\n",
    "t=date_find(c)\n",
    "\n",
    "### Finding attributes for check\n",
    "for i in range (0,len(c)):\n",
    "    #print(i)\n",
    "    if c[i] in 'sales':\n",
    "        tp=1\n",
    "    elif c[i] in 'number':\n",
    "        nm=1\n",
    "    elif c[i] in 'totalprice':\n",
    "        tp=1\n",
    "    elif c[i]=='quantity':\n",
    "        qt=1   \n",
    "    elif c[i]=='top':\n",
    "        #print(c[i+1])\n",
    "        if c[i+1] in['article','articles']:\n",
    "            topa =1\n",
    "        elif c[i+1] in ['brands','brand']:\n",
    "            topb =1\n",
    "        \n",
    "        \n",
    "### Finding Categorical Variable List and String\n",
    "for row in df.iterrows():\n",
    "    s=\" \"+str(row[1][0])+\" \"\n",
    "    if isSubstring(s, chatentry) != -1:\n",
    "        cn=1\n",
    "        print(row[1][0])\n",
    "        c1.append(row[1][0])\n",
    "        cbn=cbn+\"'\"+str(row[1][0])+\"'\"+\",\"\n",
    "        \n",
    "        \n",
    "### Finding Sub-Categorical Variable List and String\n",
    "for row in df1.iterrows():\n",
    "    s1=\" \"+str(row[1][0])+\" \"\n",
    "    if isSubstring(s1, chatentry) != -1:\n",
    "       scn=1\n",
    "       #print(row[1][0])\n",
    "       subc.append(row[1][0])\n",
    "       ebn=ebn+\"'\"+str(row[1][0])+\"'\"+\",\"\n",
    "        \n",
    "        \n",
    "### Finding Brand Variable List and String\n",
    "for row in df2.iterrows():\n",
    "    s2=\" \"+str(row[1][0])+\" \"\n",
    "    if isSubstring(s2, chatentry) != -1:\n",
    "       bn=1\n",
    "       #print(row[1][0])\n",
    "       bn1.append(row[1][0])\n",
    "       gbn=gbn+\"'\"+str(row[1][0])+\"'\"+\",\"\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "### Removing The last , from all categorical , sub -categorical and bramd variables \n",
    "gbn=gbn[0:(len(gbn)-1)]\n",
    "ebn=ebn[0:(len(ebn)-1)]\n",
    "cbn=cbn[0:(len(cbn)-1)]\n",
    "\n",
    "\n",
    "### check list of findings : ---> \n",
    "#print(dt)\n",
    "#print(t)\n",
    "#print(tp)\n",
    "#print(nm)\n",
    "#print(qt)\n",
    "#print(cn)\n",
    "#print(scn)\n",
    "#print(bn)\n",
    "#print(bn1)\n",
    "#print(subc)        \n",
    "#print(c1)\n",
    "#print(gbn)\n",
    "#print(ebn)\n",
    "#print(cbn)\n",
    "#print(topa)\n",
    "#print(topb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Basic Queries\n",
    "\n",
    "Understanding about articles and brands depending on whether date is present or is given in terms of weeks years today or yesterday we constitute 4 queries which also provide a solution if at all more one extraneos dates are given as in provides a list solution to it \n",
    "\n",
    "we have subdivided the main code to two sub parts denodet by dt is dt =0 ie extraneous date  is absent we proceed checking condition of presence of bn scn cn etc using the flag variables and similarly use between and in function to activate the query \n",
    "similarly id dt !=0 then we convert dt to t which is our date variable which further goes into the same queries .\n",
    "This is noting but an effective way to check the presence of brand name , sub brand name , category name or none of them presence in date given or date not given case .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if topa == 1 and dt == 0 :\n",
    "    query = \"(select article_id , sum(total_price) as tp  from  bills where sale_date >= '\"+str(t)+\"' group by article_id)\"\n",
    "    f = spark.sql(query) \n",
    "    #f.show()\n",
    "    f.dropDuplicates().createOrReplaceTempView(\"totsalesart\")\n",
    "    q = \" select article_id , sum(total_price) , a.name from article as a join bills as b where b.article_id = a.id and  sale_date >= '\"+str(t)+\"' group by b.article_id,a.name having sum(total_price) = (select max(tp) from totsalesart order by max(tp) desc) \"\n",
    "    f = spark.sql(q) \n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "elif topb == 1 and dt == 0 :\n",
    "    query = \"(select article_id , sum(total_price) as tp  from  bills where sale_date >= '\"+str(t)+\"' group by article_id)\"\n",
    "    f = spark.sql(query) \n",
    "    #f.show()\n",
    "    f.dropDuplicates().createOrReplaceTempView(\"totsalesbrnd\")\n",
    "    q = \" select b.article_id , sum(total_price) , a.brand_name from hierarchy as a join bills as b where b.article_id = a.article_id and  sale_date >= '\"+str(t)+\"' group by b.article_id,a.brand_name having sum(total_price) = (select max(tp) from totsalesbrnd order by max(tp) desc) \"\n",
    "    f = spark.sql(q) \n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "elif topa ==1 and dt !=0:\n",
    "    t=dt\n",
    "    query = \"(select article_id , sum(total_price) as tp  from  bills where sale_date in (\"+str(t)+\") group by article_id)\"\n",
    "    f = spark.sql(query) \n",
    "    #f.show()\n",
    "    f.dropDuplicates().createOrReplaceTempView(\"totsalesart\")\n",
    "    q = \" select article_id , sum(total_price) , a.name from article as a join bills as b where b.article_id = a.id and  sale_date in (\"+str(t)+\") group by b.article_id,a.name having sum(total_price) = (select max(tp) from totsalesart order by max(tp) desc) \"\n",
    "    f = spark.sql(q) \n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "elif topb==1 and dt !=0:\n",
    "    t=dt\n",
    "    query = \"(select article_id , sum(total_price) as tp  from  bills where sale_date in (\"+str(t)+\") group by article_id)\"\n",
    "    f = spark.sql(query) \n",
    "    #f.show()\n",
    "    f.dropDuplicates().createOrReplaceTempView(\"totsalesbrnd\")\n",
    "    q = \" select b.article_id , sum(total_price) , a.brand_name from hierarchy as a join bills as b where b.article_id = a.article_id and  sale_date in (\"+str(t)+\") group by b.article_id,a.brand_name having sum(total_price) = (select max(tp) from totsalesbrnd order by max(tp) desc) \"\n",
    "    f = spark.sql(q) \n",
    "    f.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if dt == 0:\n",
    "\n",
    "    #cn + scn + bn \n",
    "    # number\n",
    "    if cn==1 and scn==1 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn + bn \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==1 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn + bn \n",
    "    #  total price\n",
    "    if cn==1 and scn==1 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn + scn + bn\n",
    "    # quantity\n",
    "    if cn==1 and scn==1 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn + bn\n",
    "    if cn==1 and scn==0 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  + bn \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==0 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  + bn \n",
    "    #  total price\n",
    "    if cn==1 and scn==0 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn  + bn\n",
    "    # quantity\n",
    "    if cn==1 and scn==0 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # scn + bn \n",
    "    # number\n",
    "    if cn==0 and scn==1 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # scn + bn \n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==1 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # scn + bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==1 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # scn + bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==1 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn + scn \n",
    "    # number\n",
    "    if cn==1 and scn==1 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.subcategory_name,h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.subcategory_name,h.category_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn  \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==1 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.subcategory_name,h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn  \n",
    "    #  total price\n",
    "    if cn==1 and scn==1 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.subcategory_name,h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn + scn \n",
    "    # quantity\n",
    "    if cn==1 and scn==1 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.subcategory_name,h.category_name from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name  \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # scn  \n",
    "    # number\n",
    "    if cn==0 and scn==1 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.subcategory_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #scn\n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==1 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.subcategory_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\") group by b.article_id , h.subcategory_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #scn \n",
    "    #  total price\n",
    "    if cn==0 and scn==1 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.subcategory_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name\"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #scn\n",
    "    # quantity\n",
    "    if cn==0 and scn==1 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.subcategory_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn \n",
    "    # number\n",
    "    if cn==1 and scn==0 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==0 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.category_name from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn \n",
    "    #  total price\n",
    "    if cn==1 and scn==0 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn \n",
    "    # quantity\n",
    "    if cn==1 and scn==0 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.category_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.category_name in (\"+str(cbn)+\") group by b.article_id , h.category_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bn \n",
    "    # number\n",
    "    if cn==0 and scn==0 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*) , brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.brand_name in (\"+str(gbn)+\") group by b.article_id , brand_name \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==0 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00' and h.brand_name in (\"+str(gbn)+\") group by b.article_id , brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==0 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price) ,brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==0 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity) ,brand_name  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #all absent\n",
    "    # number\n",
    "    if cn==0 and scn==0 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*)  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==0 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price)  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==0 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price)   from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==0 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity)   from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date >= '\"+str(t)+\" 00:00:00'  \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "if dt !=0:\n",
    "    t=dt\n",
    "    #cn + scn + bn \n",
    "    # number\n",
    "    if cn==1 and scn==1 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn + bn \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==1 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn + bn \n",
    "    #  total price\n",
    "    if cn==1 and scn==1 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn + scn + bn\n",
    "    # quantity\n",
    "    if cn==1 and scn==1 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn + bn\n",
    "    if cn==1 and scn==0 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  + bn \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==0 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  + bn \n",
    "    #  total price\n",
    "    if cn==1 and scn==0 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn  + bn\n",
    "    # quantity\n",
    "    if cn==1 and scn==0 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # scn + bn \n",
    "    # number\n",
    "    if cn==0 and scn==1 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # scn + bn \n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==1 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # scn + bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==1 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # scn + bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==1 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name ,b.sale_date\"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn + scn \n",
    "    # number\n",
    "    if cn==1 and scn==1 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.subcategory_name,h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.subcategory_name,h.category_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn  \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==1 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.subcategory_name,h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn + scn  \n",
    "    #  total price\n",
    "    if cn==1 and scn==1 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.subcategory_name,h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn + scn \n",
    "    # quantity\n",
    "    if cn==1 and scn==1 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.subcategory_name,h.category_name,b.sale_date from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id,h.subcategory_name,h.category_name,b.sale_date  \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # scn  \n",
    "    # number\n",
    "    if cn==0 and scn==1 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.subcategory_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #scn\n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==1 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.subcategory_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\") group by b.article_id , h.subcategory_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #scn \n",
    "    #  total price\n",
    "    if cn==0 and scn==1 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.subcategory_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name,b.sale_date\"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #scn\n",
    "    # quantity\n",
    "    if cn==0 and scn==1 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.subcategory_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.subcategory_name in (\"+str(ebn)+\")  group by b.article_id , h.subcategory_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #cn \n",
    "    # number\n",
    "    if cn==1 and scn==0 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn  \n",
    "    # qunatity + total price\n",
    "    if cn==1 and scn==0 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),h.category_name,b.sale_date from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    #cn \n",
    "    #  total price\n",
    "    if cn==1 and scn==0 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.category_name in (\"+str(cbn)+\")  group by b.article_id , h.category_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    #cn \n",
    "    # quantity\n",
    "    if cn==1 and scn==0 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),h.category_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.category_name in (\"+str(cbn)+\") group by b.article_id , h.category_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bn \n",
    "    # number\n",
    "    if cn==0 and scn==0 and bn==1 and nm==1:\n",
    "        query = \"SELECT count(*) , brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , brand_name,b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==0 and bn==1 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") and h.brand_name in (\"+str(gbn)+\") group by b.article_id , brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==0 and bn==1 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price) ,brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==0 and bn==1 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity) ,brand_name,b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\")  and h.brand_name in (\"+str(gbn)+\") group by b.article_id , h.brand_name,b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #all absent\n",
    "    # number\n",
    "    if cn==0 and scn==0 and bn==0 and nm==1:\n",
    "        query = \"SELECT count(*),b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") group by b.sale_date \"\n",
    "        #print(query)\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # qunatity + total price\n",
    "    if cn==0 and scn==0 and bn==0 and tp==1 and qt==1 and nm==0:\n",
    "        query = \"SELECT sum(quantity) , sum(total_price),b.sale_date  from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") group by b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "\n",
    "    # bn \n",
    "    #  total price\n",
    "    if cn==0 and scn==0 and bn==0 and tp==1 and qt==0:\n",
    "        query = \"SELECT sum(total_price),b.sale_date   from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") group by b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()\n",
    "    # bn\n",
    "    # quantity\n",
    "    if cn==0 and scn==0 and bn==0 and tp==0 and qt==1:\n",
    "        query = \"SELECT sum(quantity),b.sale_date   from bills as b join hierarchy as h where b.article_id = h.article_id and  b.sale_date in (\"+str(t)+\") group by b.sale_date \"\n",
    "        f = spark.sql(query)\n",
    "        f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
